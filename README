This repository holds all research and code for my thesis project.
The main branch is used to display the code in a simplified way, and the preprod branch is used to actually run the code and is less 'pretty'.

My project took the form of multiple experiments, and is made of a few main sections:

    - Fisheye camera person detection and counting
        - Using RAPiD rotated bounding boxes and tracking
        - Using YOLOv5 detection with tracking
        - Using YOLOv8 detection with tracking
    - Conventional top-down camera at doorways
        - Using YOLOv5 detection with tracking
        - Using YOLOv8 detection with tracking
    - Depth camera above doorways without AI
        - Custom written code using Intel Realsense D435i camera

For my project, I was experimenting with and observing multiple solutions for detecting and counting the number of people in an enclosed space - for use in public transport or classrooms.
For each solution, I came to different opinions on how suitable it would be, and what the major pros or cons are for it.

For more details on each solution or experiment, please go to their respective folders in this repository.

Regarding datasets, I tested multiple options for training and testing models, mostly for the fisheye related data as that was harder to find:
    Fisheye:
    - Mirror Worlds Challenge (https://www2.icat.vt.edu/mirrorworlds/challenge/index.html)
    - HABBOF (https://vip.bu.edu/projects/vsns/cossy/datasets/habbof/)
    - CEPDOF (https://vip.bu.edu/projects/vsns/cossy/datasets/cepdof/) - more frames and human objects, and more challenges like crowds (could be best for tracking too)
    - WEPDTOF (https://vip.bu.edu/projects/vsns/cossy/datasets/wepdtof/)
    - FRIDA (https://vip.bu.edu/projects/vsns/cossy/datasets/frida/)
    Topdown:
    - TVPR (https://vrai.dii.univpm.it/re-id-dataset) and (https://www.youtube.com/watch?v=ReKpjZDRjiE)
    - person_topv2 (https://universe.roboflow.com/otavio-souza-wq69t/person_topv2)
    - head-detection-nej1a (https://universe.roboflow.com/head-znpny/head-detection-nej1a)
    - human-head-detection (https://universe.roboflow.com/pavel-vasiliev/human-head-detection)

Below are the different models I used or researched and their respective sources:
    RAPiD - https://github.com/duanzhiihao/RAPiD & https://vip.bu.edu/projects/vsns/cossy/fisheye/rapid/
        - Is highly accurate at most people in the close vicinity (>90%), but fails to pick up people at the very edge of the camera's range due to confidence threshold limits
        - Source code is difficult to use and adapt
        - Lacks complex tracking

    YOLOv5 with rotated bounding boxes - https://github.com/hukaixuan19970627/yolov5_obb
        - Uses weird format of listing each vertice with xi,yi... instead of x,y,w,h,degree
        - Could have been useful, but conversion of formatting for the bounding boxes is too difficult to do for thousands of images

    YOLOv5_StrongSORT - https://github.com/mikel-brostrom/Yolov5_StrongSORT_OSNet 
        - The initial detection from the pretrained YOLOv5 struggles with people that appear upside down due to being trained on COCO, therefore the tracking overcounts the number of people
        - Adding reidentification helped improve this massively, but pretrained YOLO still struggles with upside down people
        - Training the model improved detection massively, but the model would still drop out when people were directly underneath the camera.
            - Could be worth training even more on more varied datasets
        - TRACKERS: Strongsort was much better than ocsort but took a bit longer to process. Bytetrack seemed the best taking the least time and providing the best results
            - python track.py --tracking-method bytetrack --source 'https://www.youtube.com/watch?v=qBl1tPwyJ2wlist=PLKjRNrBNA-nzzv4KqqdeMHMtq26kue5ZR&index=5' --classes 0 --reid-weights osnet_x0_25_market1501.pt
            - YOLOv5m (medium size) seemed more accurate but slower, YOLOv5s (small size) seemed much faster but would lose detection more often. YOLOv5l (large size) had the best results but took a little longer per frame

## USEFUL COMMANDS ##

    - COMMAND FOR TRACKING ON VIDEO FROM BEDROOM
        python3 track.py --tracking-method bytetrack --source Dataset/bedroom/bedroom_2_480.mp4 --yolo-weights tuned_models/bus_heads_300epochs/weights/best.pt --classes 0 --show-vid --reid-weights osnet_x0_25_market1501.pt

    - COMMAND FOR TRAINING YOLOV5 MODEL
        python3 yolov5/train.py --img 640 --batch-size -1 --epochs 100 --data dataset/data.yaml --weights yolov5s.pt

    - YOUTUBE VIDEO TOP DOWN FOR TESTING
        https://www.youtube.com/watch?v=qBl1tPwyJ2w&list=PLKjRNrBNA-nzzv4KqqdeMHMtq26kue5ZR&index=5

######## TODO ########
    - formalise each section of this project
    - update the main project structure to include depth cam stuff and doorframe stuff
    - try to get it all up on github

################
